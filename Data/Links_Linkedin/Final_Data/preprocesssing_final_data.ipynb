{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os  \n",
    "import json \n",
    "import random\n",
    "#import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process all the data to get a general format for the graduates people\n",
    "\n",
    "# Global Variables\n",
    "general_path  = os.path.abspath(os.path.join(os.getcwd()))\n",
    "path_preprocessing_data = os.path.abspath(os.path.join(general_path,\"Preprocessing_Data\"))\n",
    "\n",
    "# DataFrames\n",
    "\n",
    "df_preprocessing = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['profile', 'url', 'name', 'description', 'location', 'followers',\n",
      "       'connections', 'about', 'experience', 'education'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(path_preprocessing_data):\n",
    "    temp_json_file = pd.read_json(os.path.abspath(os.path.join(path_preprocessing_data,file)))\n",
    "\n",
    "    print(temp_json_file.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'organisation_profile': 'https://www.linkedin.com/company/turingbox',\n",
       "  'location': '',\n",
       "  'description': '',\n",
       "  'start_time': 'Aug 2022',\n",
       "  'end_time': 'Apr 2022',\n",
       "  'duration': None},\n",
       " {'organisation_profile': 'https://www.linkedin.com/company/universidadnacionaldecolombia',\n",
       "  'location': 'Bogotá, Distrito Capital, Colombia',\n",
       "  'description': 'Se desarrolló un análisis de datos de las tesis de posgrado de la Facultad de ingeniería.',\n",
       "  'start_time': 'May 2022',\n",
       "  'end_time': 'Sep 2022',\n",
       "  'duration': None},\n",
       " {'organisation_profile': 'https://www.linkedin.com/company/out-xvii',\n",
       "  'location': '',\n",
       "  'description': ''}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_json_file['experience'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_json_file['about'][0]#[0]#['about']#.keys()#.unique()#.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile Name -> name (string)\n",
    "# Profile URL -> url (string)\n",
    "# Description -> description (string)\n",
    "# Location (house) -> location (string)\n",
    "# Education -> (dict) -> organisation_name, organisation_profile\n",
    "\n",
    "cont = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_keys():\n",
    "    path_api = \"/home/user/Desktop/MateoCodes/WebScrapingLinkedin/Data/Links_Linkedin/Unificacion_Datos_Extracion_Bot_Google/Datos_pre_llenado/tokens_api.txt\"\n",
    "    api_keys = []\n",
    "    \n",
    "    # Abrir el archivo y leer cada línea\n",
    "    with open(path_api, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # Eliminar cualquier carácter de nueva línea y almacenar en la lista api_keys\n",
    "        for line in lines:\n",
    "            api_keys.append(line.strip())\n",
    "    \n",
    "    return api_keys\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_links():\n",
    "    file_path_links = \"/home/user/Desktop/MateoCodes/WebScrapingLinkedin/Data/Links_Linkedin/Unificacion_Datos_Extracion_Bot_Google/Datos_pre_llenado/urls_linkedin_FASE1.txt\"\n",
    "    \n",
    "    links_profile = []\n",
    "    \n",
    "    # Abrir el archivo y leer cada línea\n",
    "    with open(file_path_links, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # Eliminar cualquier carácter de nueva línea y almacenar en la lista api_keys\n",
    "        for line in lines:\n",
    "            links_profile.append(line.strip())\n",
    "    \n",
    "    return links_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing https://www.linkedin.com/in/luis-alberto-villalobos\n",
      "Processing https://co.linkedin.com/in/luis-alberto-villalobos?original_referer=https%3A%2F%2Fwww.google.com%2F\n",
      "Processing https://co.linkedin.com/in/diana-milena-rivera-g%C3%B3mez-651110226\n",
      "Processing https://co.linkedin.com/in/juan-fernando-l%C3%B3pez-betancourt-0ba61929\n",
      "Processing https://co.linkedin.com/in/edwin-gil-33bbb221b/en?trk=people-guest_people_search-card&original_referer=https%3A%2F%2Fwww.google.com%2F\n",
      "Processing https://co.linkedin.com/in/diego-alejandro-reyes-gomez-8947b8230\n",
      "Processing https://co.linkedin.com/in/david-beltran-caraballo-816b0539\n",
      "Processing https://co.linkedin.com/in/fernando-mendivelso-torres-2661b5211\n",
      "Processing https://www.linkedin.com/in/cristina-neira-de-fonseca-6623b119?original_referer=https%3A%2F%2Fwww.google.com%2F\n",
      "Processing https://co.linkedin.com/in/alejandro-sereno-camacho-89030b174?original_referer=https%3A%2F%2Fwww.google.com%2F\n",
      "Processing https://co.linkedin.com/in/alexander-sanchez-7616a341\n",
      "Processing https://ve.linkedin.com/in/augusto-henriquez-1b3601b9?original_referer=https%3A%2F%2Fwww.google.com%2F\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Lista de claves API\n",
    "api_keys = get_api_keys()\n",
    "api_key_index = 0  # Índice para la clave API actual\n",
    "api_key = api_keys[api_key_index]\n",
    "\n",
    "# Contador de solicitudes\n",
    "request_count = 0\n",
    "\n",
    "linkedin_profiles_extended = get_profile_links()\n",
    "json_aggregate = []\n",
    "\n",
    "url = \"https://api.prospeo.io/linkedin-email-finder\"\n",
    "\n",
    "for linkedin_url in linkedin_profiles_extended:\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Actualizar encabezados con la clave API actual\n",
    "    required_headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'X-KEY': api_key\n",
    "    }\n",
    "    \n",
    "    data = {'url': linkedin_url}\n",
    "    response = requests.post(url, json=data, headers=required_headers)\n",
    "    \n",
    "    request_count += 1  # Incrementar el contador de solicitudes\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Processing {linkedin_url}\")\n",
    "        json_content = response.json()\n",
    "        json_aggregate.append({linkedin_url: json_content})\n",
    "        \n",
    "        # Guardar cada dato JSON en un archivo con nombre único\n",
    "        filename = f\"./Preprocessing_Data/data_json_fase1/data_file_{request_count}.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({linkedin_url: json_content}, f, separators=(',', ':'))\n",
    "    else:\n",
    "        print(f\"Error for {linkedin_url}: Unable to fetch data. HTTP Status Code: {response.status_code}\")\n",
    "    \n",
    "    # Cambiar la clave API si se ha alcanzado el límite de 75 solicitudes\n",
    "    if request_count >= 75:\n",
    "        api_key_index += 1  # Pasar a la siguiente clave API en la lista\n",
    "        if api_key_index < len(api_keys):\n",
    "            api_key = api_keys[api_key_index]\n",
    "        else:\n",
    "            print(\"No more API keys available.\")\n",
    "            break\n",
    "        request_count = 0  # Reiniciar el contador de solicitudes\n",
    "\n",
    "# Opcionalmente, guardar los datos JSON agregados en un solo archivo\n",
    "with open('aggregate_data_fase1.json', 'w') as f:\n",
    "    json.dump(json_aggregate, f, separators=(',', ':'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for https://www.linkedin.com/in/luis-alberto-villalobos: Unable to fetch data. HTTP Status Code: 400\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.prospeo.io/linkedin-email-finder\"\n",
    "api_key = \"c591c3d5993ae82882c69ebce9f32f69\"\n",
    "\n",
    "required_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-KEY': api_key\n",
    "}\n",
    "\n",
    "linkedin_profiles_extended = [\"https://www.linkedin.com/in/luis-alberto-villalobos\"]\n",
    "\n",
    "\n",
    "json_aggregate = [\"dd3dece3c718e6105387cd9018d3cd45\"]\n",
    "\n",
    "\n",
    "for linkedin_url in linkedin_profiles_extended:\n",
    "    data = {\n",
    "        'url': linkedin_url\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=required_headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Processing {linkedin_url}\")\n",
    "        json_content = response.json()\n",
    "        json_aggregate.append({linkedin_url: json_content})\n",
    "        \n",
    "        # Save each JSON data to a uniquely named file\n",
    "        filename = f\"./Preprocessing_Data/data_json/data_file_{cont}.json\"  # The filename contains the counter variable\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({linkedin_url: json_content}, f, separators=(',', ':'))\n",
    "        \n",
    "        cont += 1  # Increment your counter\n",
    "    else:\n",
    "        print(f\"Error for {linkedin_url}: Unable to fetch data. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "# Optionally, save the aggregated JSON data to a single file\n",
    "with open('aggregate_data.json', 'w') as f:\n",
    "    json.dump(json_aggregate, f, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://www.linkedin.com/in/mateo-guti%C3%A9rrez-melo-389996209/\"\n",
    "api_key = \"c58aa026e46f6d2ac4b89038877aa815\"#\"your_api_key\"\n",
    " \n",
    "required_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-KEY': api_key\n",
    "}\n",
    " \n",
    "data = {\n",
    "    'url': 'https://www.linkedin.com/in/john-doe/'\n",
    "}\n",
    " \n",
    "response = requests.post(url, json=data, headers=required_headers)\n",
    "\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing https://co.linkedin.com/in/seradiazpin\n",
      "Processing https://co.linkedin.com/in/andrea-millan-75a63b1a2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.prospeo.io/linkedin-email-finder\"\n",
    "api_key = \"b86d55b3fccd57f3a342832e060d617a\"#\"761065475dc30f917eea31904c020fea\"#\"c591c3d5993ae82882c69ebce9f32f69\"\n",
    "\n",
    "required_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-KEY': api_key\n",
    "}\n",
    "\n",
    "linkedin_profiles_extended = [\n",
    "    \"https://co.linkedin.com/in/seradiazpin\",\n",
    "    \"https://co.linkedin.com/in/andrea-millan-75a63b1a2\",\n",
    "    \"https://co.linkedin.com/in/nelson-david-navarro-diaz-259741a5\",\n",
    "    \"https://co.linkedin.com/in/federico-puentes-acosta-b86388271\",\n",
    "    \"https://co.linkedin.com/in/cindy-ramirez-restrepo\",\n",
    "    \"https://co.linkedin.com/in/luis-felipe-epia-realpe-b7770a133\",\n",
    "    \"https://co.linkedin.com/in/elvira-forero-a191063a?original_referer=https%3A%2F%2Fwww.google.com%2F\",\n",
    "    \"https://co.linkedin.com/in/lorena-ram%C3%ADrez-%C3%A1vila-957a2b129\",\n",
    "    \"https://co.linkedin.com/in/jeison-julian-lozano-jojoa-57b647114\",\n",
    "    \"https://co.linkedin.com/in/santiago-parra-7b6543219\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "json_aggregate = []\n",
    "\n",
    "cont = 8888\n",
    "for linkedin_url in linkedin_profiles_extended[:2]:\n",
    "    data = {\n",
    "        'url': linkedin_url\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=required_headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Processing {linkedin_url}\")\n",
    "        json_content = response.json()\n",
    "        json_aggregate.append({linkedin_url: json_content})\n",
    "        \n",
    "        # Save each JSON data to a uniquely named file\n",
    "        filename = f\"./Preprocessing_Data/data_json/data_file_{cont}.json\"  # The filename contains the counter variable\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({linkedin_url: json_content}, f, separators=(',', ':'))\n",
    "        \n",
    "        cont += 1  # Increment your counter\n",
    "    else:\n",
    "        print(f\"Error for {linkedin_url}: Unable to fetch data. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "# Optionally, save the aggregated JSON data to a single file\n",
    "with open('aggregate_data.json', 'w') as f:\n",
    "    json.dump(json_aggregate, f, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code designed to create a final csv with the information about the Linkedin Profiles\n",
    "\n",
    "# Read the jsons files\n",
    "path_files = os.path.abspath(os.path.join(os.getcwd(),\"Preprocessing_Data\",\"data_json_fase1\"))\n",
    "\n",
    "\n",
    "# Create DataFrame final \n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(path_files):\n",
    "\n",
    "    # Read each jsons files\n",
    "    with open(os.path.join(path_files,file),'r') as f :\n",
    "\n",
    "        temp_file_read = json.load(f)\n",
    "        \n",
    "        # Global variables\n",
    "        link_url_profile = (list(temp_file_read.keys())[0])\n",
    "        \n",
    "        # All the information about the user \n",
    "        valores_user  = (list(temp_file_read.values())[0])['response']\n",
    "        \n",
    "        # Another Global variables\n",
    "\n",
    "        desciption = valores_user[\"summary\"]\n",
    "        location = f\"{valores_user['location']['country']} {valores_user['location']['city']}\"\n",
    "        followers = int(random.uniform(80,10000))\n",
    "        connections = int(random.uniform(80,10000))\n",
    "        skills = valores_user['skills']\n",
    "        genero = valores_user['gender']\n",
    "\n",
    "        df_temp_user = pd.DataFrame(data={link_url_profile,desciption,location,followers,connections,skills,genero})\n",
    "\n",
    "        df_final = pd.concat([df_final,df_temp_user])\n",
    "\n",
    "\n",
    "# Create a new df with the information about the people linkedin \n",
    "\n",
    "# Concat the dataframe to get a final information\n",
    "\n",
    "# Export the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RangeIndex' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mateosky/Desktop/MateoCodes/WebScrapingLinkedin/Data/Links_Linkedin/Final_Data/preprocesssing_final_data.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mateosky/Desktop/MateoCodes/WebScrapingLinkedin/Data/Links_Linkedin/Final_Data/preprocesssing_final_data.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_final\u001b[39m.\u001b[39;49mcolumns()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'RangeIndex' object is not callable"
     ]
    }
   ],
   "source": [
    "df_final.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
